{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljp238/miniconda3/envs/samlidar/lib/python3.9/site-packages/pyproj/__init__.py:95: UserWarning: pyproj unable to set database path.\n",
      "  _pyproj_global_context_initialize()\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import pdal \n",
    "import laspy\n",
    "import numpy as np \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uvars import eba_laz_dir, eba_tif_dir,eba_lazclf_dir,transect_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdal_quick_info(laz_path):\n",
    "    reader = pdal.Reader(laz_path) # sensitive to resolution, can pass argument here \n",
    "    pipeline = reader.pipeline()\n",
    "    qi = pipeline.quickinfo \n",
    "    return qi,pipeline\n",
    "\n",
    "def pdal_pc_classes(pipeline):\n",
    "    pipeline.execute()\n",
    "    arrays = pipeline.arrays\n",
    "    if len(arrays) == 0:\n",
    "        print(\"No point data found in the file.\")\n",
    "    \n",
    "    classification_values = arrays[0]['Classification']\n",
    "    unique_classes = np.unique(classification_values)\n",
    "    print(f\"Unique classifications: {unique_classes}\")\n",
    "    return unique_classes\n",
    "\n",
    "def generate_dtm(laz, tif, res=10,outfn=\"mean\"):\n",
    "    ti = time.perf_counter()\n",
    "\n",
    "    tif = tif.replace('.tif', f\"_DTM{str(res)}_{outfn}.tif\")\n",
    "\n",
    "    if os.path.isfile(tif):\n",
    "        print(f\"file alredy exist...\\n{tif}\")\n",
    "        return tif \n",
    "    \"\"\"Extracts ground points and generates a DTM.\"\"\"\n",
    "    print(f\"Generating DTM: {laz} \\n-> {tif}\")\n",
    "\n",
    "    pipeline = pdal.Reader(laz)\n",
    "    pipeline |= pdal.Filter.expression(expression=\"Classification == 2\")\n",
    "    pipeline |= pdal.Writer.gdal(\n",
    "        filename=tif, gdalopts=\"tiled=yes, compress=deflate\", nodata=-9999,\n",
    "        output_type=outfn, resolution=res\n",
    "    )\n",
    "    \n",
    "    pipeline.execute()\n",
    "    tf = time.perf_counter() - ti \n",
    "    print(f\"DTM saved to {tif}\")\n",
    "    print(f\"run.time = {tf/60} min(s)\")\n",
    "    return tif\n",
    "\n",
    "def clf_pointcloud(laz, lazo, method=\"smrf\"):\n",
    "    ti = time.perf_counter()\n",
    "    print(\"\"\"Classifies ground points in a point cloud and saves to LAZ.\"\"\")\n",
    "    lazo = lazo.replace('.laz', f'_{method}.laz')\n",
    "\n",
    "    if os.path.isfile(lazo):\n",
    "        print(f\"file aready created {lazo}\")\n",
    "        return lazo \n",
    "    \n",
    "    pipeline = pdal.Reader(laz)\n",
    "    pipeline |= pdal.Filter.expression(expression=\"Classification != 7\")\n",
    "    pipeline |= pdal.Filter.assign(assignment=\"Classification[:]=0\")\n",
    "    if method == 'smrf':\n",
    "        pipeline |= pdal.Filter.smrf()\n",
    "    elif method == 'csf':\n",
    "        pipeline |= pdal.Filter.csf()\n",
    "    \n",
    "    pipeline |= pdal.Writer.las(filename=lazo, compression=\"laszip\")\n",
    "    #https://pdal.io/en/latest/stages/writers.las.html\n",
    "    pipeline.execute()\n",
    "    print(f\"Reclassified point cloud saved to \\n{lazo}\")\n",
    "    tf = time.perf_counter() - ti \n",
    "    print(f\"run.time = {tf/60} min(s)\")\n",
    "    return lazo\n",
    "\n",
    "def pointcloud_to_dtmtiff(laz,tif,lazo,res=10,outfn=\"mean\",method=\"smrf\"):\n",
    "    qi,pipeline = pdal_quick_info(laz)\n",
    "    unique_classes = pdal_pc_classes(pipeline)\n",
    "    # Check if 2 is in unique_classes\n",
    "    if 2 in unique_classes:\n",
    "        print('YES:::PointCloud ALREADY classified...')\n",
    "        generate_dtm(laz, tif, res=res,outfn=outfn)\n",
    "    else:\n",
    "        print('NO:::PointCloud NOT YET classified...')\n",
    "        lazo = clf_pointcloud(laz, lazo, method=method)\n",
    "        generate_dtm(lazo, tif, res=res,outfn=outfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:transectos_tocantins :: 1 laz\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_tocantins/NP_T-0171.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_tocantins/NP_T-0171_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_tocantins/NP_T-0171_DTM10_mean.tif\n",
      "run.time = 0.37328819793328877 min(s)\n",
      "1:transectos_para_p5 :: 9 laz\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_001.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_001_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_001_DTM10_mean.tif\n",
      "run.time = 0.13806041015001635 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_002.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_002_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_002_DTM10_mean.tif\n",
      "run.time = 0.11092718015036857 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_003.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_003_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_003_DTM10_mean.tif\n",
      "run.time = 0.11962806683344146 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_004.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_004_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_004_DTM10_mean.tif\n",
      "run.time = 0.10835632509988499 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_005.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_005_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_005_DTM10_mean.tif\n",
      "run.time = 0.10793156516641224 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_006.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_006_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_006_DTM10_mean.tif\n",
      "run.time = 0.0937949561169565 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_007.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_007_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_007_DTM10_mean.tif\n",
      "run.time = 0.09577027844982998 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_008.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_008_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_008_DTM10_mean.tif\n",
      "run.time = 0.10209277145040688 min(s)\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Generating DTM: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_para_p5/NP_T-1016_009.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_009_DTM10_mean.tif\n",
      "DTM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_para_p5/NP_T-1016_009_DTM10_mean.tif\n",
      "run.time = 0.10593315408332274 min(s)\n"
     ]
    }
   ],
   "source": [
    "for i, location in enumerate(transect_names):\n",
    "    if i > 1: break\n",
    "    \n",
    "    loc_laz_files = glob(f\"{eba_laz_dir}/{location}/*.laz\")\n",
    "    loc_tif_dir = f\"{eba_tif_dir}/{location}\"\n",
    "    loc_lazo_dir = f\"{eba_lazclf_dir}/{location}\"\n",
    "    os.makedirs(loc_tif_dir, exist_ok=True)\n",
    "    os.makedirs(loc_lazo_dir, exist_ok=True)\n",
    "    print(f\"{i}:{location} :: {len(loc_laz_files)} laz\")\n",
    "    for laz in loc_laz_files:\n",
    "        btif = os.path.basename(laz).replace('.laz', '.tif')\n",
    "        tif = f\"{loc_tif_dir}/{btif}\"\n",
    "        lazo = f\"{loc_lazo_dir}/{os.path.basename(laz)}\"\n",
    "        pointcloud_to_dtmtiff(laz,tif,lazo,res=10,outfn=\"mean\",method=\"smrf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointcloud2dtm(laz,tif,lazo,res=10,outfn=\"mean\",method=\"smrf\"):\n",
    "    qi,pipeline = pdal_quick_info(laz)\n",
    "    unique_classes = pdal_pc_classes(pipeline)\n",
    "    # Check if 2 is in unique_classes\n",
    "    if 2 in unique_classes:\n",
    "        print('YES:::PointCloud ALREADY classified...')\n",
    "        generate_dtm(laz, tif, res=res,outfn=outfn)\n",
    "    else:\n",
    "        print('NO:::PointCloud NOT YET classified...')\n",
    "        lazo = clf_pointcloud(laz, lazo, method=method)\n",
    "        generate_dtm(lazo, tif, res=res,outfn=outfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classifications: [0 2 4]\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "qi,pipeline = pdal_quick_info(laz)\n",
    "unique_classes = pdal_pc_classes(pipeline)\n",
    "# Check if 2 is in unique_classes\n",
    "if 2 in unique_classes:\n",
    "    print('Yes')\n",
    "    generate_dtm(laz, tif, res=10,outfn=\"mean\")\n",
    "else:\n",
    "    print('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samlidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
