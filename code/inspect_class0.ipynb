{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 0\n",
    "case 1 - Laz yes classifier:\n",
    "- dsm with 0\n",
    "- dsm without 0  \n",
    "- compare \n",
    "\n",
    "case 2: Laz not classified \n",
    "- get the number of classes and unique values [x]\n",
    "- dsm with 0 \n",
    "- dsm without 0 \n",
    "- compare \n",
    "\n",
    "\n",
    "no difference we decided to go with last return and max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import pdal \n",
    "import numpy as np \n",
    "import time \n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from uvars import eba_laz_dir, eba_tif_dir,eba_lazclf_dir,transect_names \n",
    "\n",
    "def pdal_quick_info(laz_path):\n",
    "    reader = pdal.Reader(laz_path) # sensitive to resolution, can pass argument here \n",
    "    pipeline = reader.pipeline()\n",
    "    qi = pipeline.quickinfo \n",
    "    return qi,pipeline\n",
    "\n",
    "\n",
    "def pdal_pc_classes(pipeline):\n",
    "    pipeline.execute()\n",
    "    arrays = pipeline.arrays\n",
    "    if len(arrays) == 0:\n",
    "        print(\"No point data found in the file.\")\n",
    "    \n",
    "    classification_values = arrays[0]['Classification']\n",
    "    unique_classes = np.unique(classification_values)\n",
    "    print(f\"Unique classifications: {unique_classes}\")\n",
    "    return unique_classes\n",
    "\n",
    "def clf_pointcloud(laz, lazo, method=\"smrf\"):\n",
    "    ti = time.perf_counter()\n",
    "    print(\"\"\"Classifies ground points in a point cloud and saves to LAZ.\"\"\")\n",
    "    lazo = lazo.replace('.laz', f'_{method}.laz')\n",
    "\n",
    "    if os.path.isfile(lazo):\n",
    "        print(f\"file aready created {lazo}\")\n",
    "        return lazo \n",
    "    \n",
    "    pipeline = pdal.Reader(laz)\n",
    "    pipeline |= pdal.Filter.expression(expression=\"Classification != 7\")\n",
    "    pipeline |= pdal.Filter.assign(assignment=\"Classification[:]=0\")\n",
    "    if method == 'smrf':\n",
    "        pipeline |= pdal.Filter.smrf()\n",
    "    elif method == 'csf':\n",
    "        pipeline |= pdal.Filter.csf()\n",
    "    \n",
    "    pipeline |= pdal.Writer.las(filename=lazo, compression=\"laszip\")\n",
    "    #https://pdal.io/en/latest/stages/writers.las.html\n",
    "    pipeline.execute()\n",
    "    print(f\"Reclassified point cloud saved to \\n{lazo}\")\n",
    "    tf = time.perf_counter() - ti \n",
    "    print(f\"run.time = {tf/60} min(s)\")\n",
    "    return lazo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare mean, and max here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pdal\n",
    "\n",
    "def generate_dsm_by_range(laz, tif, res=10, outfn=\"mean\",lc=0,hc=4):\n",
    "    ti = time.perf_counter()\n",
    "\n",
    "    # Define the output file name\n",
    "    tif = tif.replace('.tif', f\"_rangeDSM{str(res)}_{outfn}_{lc}{hc}.tif\")\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.isfile(tif):\n",
    "        print(f\"File already exists...\\n{tif}\")\n",
    "        return tif \n",
    "\n",
    "    print(f\"Extracting points (classes {lc} to {hc}) and generating a DSM.\")\n",
    "    print(f\"Generating DSM: {laz} \\n-> {tif}\")\n",
    "\n",
    "    # Define the PDAL pipeline\n",
    "    pipeline = pdal.Reader(laz)\n",
    "    # Keep classifications 0 to 5 for DSM\n",
    "    pipeline |= pdal.Filter.range(limits=f\"Classification[{lc}:{hc}]\")\n",
    "    # Write to GeoTIFF with specified resolution and compression\n",
    "    pipeline |= pdal.Writer.gdal(\n",
    "        filename=tif,\n",
    "        gdalopts=\"tiled=yes,compress=deflate\",\n",
    "        nodata=-9999,\n",
    "        output_type=outfn,\n",
    "        resolution=res\n",
    "    )\n",
    "\n",
    "    # Execute the pipeline\n",
    "    pipeline.execute()\n",
    "    tf = time.perf_counter() - ti \n",
    "    print(f\"DSM saved to {tif}\")\n",
    "    print(f\"Run time = {tf / 60:.2f} minute(s)\")\n",
    "    return tif\n",
    "\n",
    "def generate_dsm_by_hag(lazo, dsm_tif, res, outfn):\n",
    "    ti = time.perf_counter() \n",
    "    \"\"\"Extracts highest points and generates a DSM.\"\"\"\n",
    "    # Define the output file name\n",
    "    tif = dsm_tif = dsm_tif.replace('.tif', f\"_hagDSM{str(res)}_{outfn}.tif\")\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.isfile(tif):\n",
    "        print(f\"File already exists...\\n{tif}\")\n",
    "        return tif \n",
    "\n",
    "    pipeline = pdal.Reader(lazo)\n",
    "    pipeline |= pdal.Filter.outlier(method=\"radius\", radius=1.0, min_k=3)  # Remove high outliers\n",
    "    #pipeline |= pdal.Filter.farthestneighbour()\n",
    "    pipeline |= pdal.Filter.hag_delaunay()  # Use HAG Delaunay triangulation for DSM\n",
    "    pipeline |= pdal.Writer.gdal(\n",
    "        filename=dsm_tif, gdalopts=\"tiled=yes, compress=deflate\", nodata=-9999,\n",
    "        output_type=outfn, resolution=res\n",
    "    )\n",
    "    \n",
    "    pipeline.execute()\n",
    "    print(f\"DSM saved to {dsm_tif}\")\n",
    "    tf = time.perf_counter() - ti \n",
    "    print(f\"DSM saved to {tif}\")\n",
    "    print(f\"Run time = {tf / 60:.2f} minute(s)\")\n",
    "\n",
    "\n",
    "def generate_dsm_by_return(laz, tif, res=10, outfn=\"mean\"):\n",
    "    ti = time.perf_counter()\n",
    "\n",
    "    # Define the output file name\n",
    "    tif = tif.replace('.tif', f\"_returnDSM_{str(res)}_{outfn}.tif\")\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.isfile(tif):\n",
    "        print(f\"File already exists...\\n{tif}\")\n",
    "        return tif \n",
    "\n",
    "    print(\"Extracting first return points and generating a DSM.\")\n",
    "    print(f\"Generating DSM by return: {laz} \\n-> {tif}\")\n",
    "\n",
    "    # Define the PDAL pipeline\n",
    "    pipeline = pdal.Reader(laz)\n",
    "    \n",
    "    # Use the return number filter to only include the first returns\n",
    "    pipeline |= pdal.Filter.range(limits=\"returnnumber[1:1]\")\n",
    "    \n",
    "    # Write to GeoTIFF with specified resolution and compression\n",
    "    pipeline |= pdal.Writer.gdal(\n",
    "        filename=tif,\n",
    "        gdalopts=\"tiled=yes,compress=deflate\",\n",
    "        nodata=-9999,\n",
    "        output_type=outfn,\n",
    "        resolution=res\n",
    "    )\n",
    "\n",
    "    # Execute the pipeline\n",
    "    pipeline.execute()\n",
    "    tf = time.perf_counter() - ti \n",
    "    print(f\"DSM saved to {tif}\")\n",
    "    print(f\"Run time = {tf / 60:.2f} minute(s)\")\n",
    "    return tif\n",
    "\n",
    "\n",
    "def pointcloud_to_dsmtiff(laz,tif,lazo,res=10,outfn=\"mean\",method=\"smrf\",lc=0,hc=4,mode=\"range\"):\n",
    "    qi,pipeline = pdal_quick_info(laz)\n",
    "    unique_classes = pdal_pc_classes(pipeline)\n",
    "    # Check if 2 is in unique_classes\n",
    "    if 2 in unique_classes:\n",
    "        print('YES:::PointCloud ALREADY classified...')\n",
    "        #generate_dtm(laz, tif, res=res,outfn=outfn)\n",
    "        if mode == \"range\":\n",
    "            generate_dsm_by_range(laz, tif, res=res, outfn=outfn,lc=lc,hc=hc)\n",
    "        elif mode == \"hag\":\n",
    "            generate_dsm_by_hag(lazo, tif, res, outfn)\n",
    "        elif mode == \"return\":\n",
    "            generate_dsm_by_return(laz, tif, res=res, outfn=outfn)\n",
    "        else:\n",
    "            print(\"mode not available...\")\n",
    "    else:\n",
    "        print('NO:::PointCloud NOT YET classified...')\n",
    "        lazo = clf_pointcloud(laz, lazo, method=method)\n",
    "        #generate_dtm(lazo, tif, res=res,outfn=outfn)\n",
    "        if mode == \"range\":\n",
    "            generate_dsm_by_range(laz, tif, res=res, outfn=outfn,lc=lc,hc=hc)\n",
    "        elif mode == \"hag\":\n",
    "            generate_dsm_by_hag(lazo, tif, res, outfn)\n",
    "        elif mode == \"return\":\n",
    "            generate_dsm_by_return(laz, tif, res=res, outfn=outfn)\n",
    "        else:\n",
    "            print(\"mode not available...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# already classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, outfn, method,lc,hc = 10, \"max\", \"csf\",0,4 # max\n",
    "mode1, mode2, mode3 = \"range\",\"return\",\"hag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:transectos_tocantins :: 1 laz\n",
      "Unique classifications: [0 2 4]\n",
      "YES:::PointCloud ALREADY classified...\n",
      "Extracting first return points and generating a DSM.\n",
      "Generating DSM by return: /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD/comprexn/transectos_tocantins/NP_T-0171.laz \n",
      "-> /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_tocantins/NP_T-0171_returnDSM_10_max.tif\n",
      "DSM saved to /media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/GeoTIFF/transectos_tocantins/NP_T-0171_returnDSM_10_max.tif\n",
      "Run time = 0.50 minute(s)\n"
     ]
    }
   ],
   "source": [
    "for i, location in enumerate(transect_names):\n",
    "    if i > 0: break\n",
    "    \n",
    "    loc_laz_files = glob(f\"{eba_laz_dir}/{location}/*.laz\")\n",
    "    loc_tif_dir = f\"{eba_tif_dir}/{location}\"\n",
    "    loc_lazo_dir = f\"{eba_lazclf_dir}/{location}\"\n",
    "    os.makedirs(loc_tif_dir, exist_ok=True)\n",
    "    os.makedirs(loc_lazo_dir, exist_ok=True)\n",
    "    print(f\"{i}:{location} :: {len(loc_laz_files)} laz\")\n",
    "    for laz in loc_laz_files:\n",
    "        btif = os.path.basename(laz).replace('.laz', '.tif')\n",
    "        tif = f\"{loc_tif_dir}/{btif}\"\n",
    "        lazo = f\"{loc_lazo_dir}/{os.path.basename(laz)}\"\n",
    "        #pointcloud_to_dsmtiff(laz,tif,lazo,res,outfn,method,lc,hc,mode1) # very expensive @thrsh30min\n",
    "        pointcloud_to_dsmtiff(laz,tif,lazo,res,outfn,method,lc,hc,mode2)\n",
    "        #pointcloud_to_dsmtiff(laz,tif,lazo,res,outfn,method,lc,hc,mode3)\n",
    "\n",
    "\n",
    "#pointcloud_to_dsmtiff(laz,tif,lazo,res=10,outfn=\"mean\",method=\"smrf\",lc=0,hc=4,mode=\"range\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it changes the logic above, lets try to understand the classes of the new laz\n",
    "# use all the othe classes except 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_laz_dir = \"/media/ljp238/12TBWolf/ARCHIEVE/BrazilEBA/POINTCLOUD_CLF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_laz_files = glob(f\"{clf_laz_dir}/*/*.laz\")\n",
    "len(clf_laz_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for laz_path in clf_laz_files:\n",
    "#     print(os.path.basename(laz_path))\n",
    "#     qi,pipeline = pdal_quick_info(laz_path)\n",
    "#     unique_classes = pdal_pc_classes(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz_path = clf_laz_files[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classifications: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samlidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
