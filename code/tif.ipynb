{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def gdal_reproj(fi, fo, epsg_code=4326):\n",
    "    if not os.path.isfile(fo):\n",
    "        cmd = f\"gdalwarp -q -t_srs EPSG:{epsg_code} {fi} {fo}\"\n",
    "        os.system(cmd)\n",
    "    else:\n",
    "        print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3111\n",
      "3110\n",
      "3111\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ornl_tif_dir = \"/media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/state\"\n",
    "ornl_dtm_dir = \"/media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dtm\"\n",
    "ornl_dsm_dir = \"/media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm\"\n",
    "\n",
    "dtm_files = glob(f\"{ornl_tif_dir}/*DTM*.tif\"); print(len(dtm_files))\n",
    "dsm_files = glob(f\"{ornl_tif_dir}/*DSM*.tif\"); print(len(dsm_files))\n",
    "\n",
    "\n",
    "idtm_files = glob(f\"{ornl_dtm_dir}/*.tif\"); print(len(idtm_files))\n",
    "idsm_files = glob(f\"{ornl_dsm_dir}/*.tif\"); print(len(idsm_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ORNL reproj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(ornl_dtm_dir, exist_ok=True)\n",
    "os.makedirs(ornl_dsm_dir, exist_ok=True)\n",
    "epsg_code=4326\n",
    "files = dsm_files\n",
    "outdir = ornl_dsm_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with ProcessPoolExecutor(50) as pex:\n",
    "        for fi in files:\n",
    "            fo = os.path.join(outdir, os.path.basename(fi))\n",
    "            pex.submit(gdal_reproj,fi,fo,epsg_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3111\n",
      "3110\n",
      "3111\n",
      "3110\n"
     ]
    }
   ],
   "source": [
    "dtm_files = glob(f\"{ornl_tif_dir}/*DTM*.tif\"); print(len(dtm_files))\n",
    "dsm_files = glob(f\"{ornl_tif_dir}/*DSM*.tif\"); print(len(dsm_files))\n",
    "\n",
    "idtm_files = glob(f\"{ornl_dtm_dir}/*.tif\"); print(len(idtm_files))\n",
    "idsm_files = glob(f\"{ornl_dsm_dir}/*.tif\"); print(len(idsm_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljp238/miniconda3/envs/samlidar/lib/python3.9/site-packages/pyproj/__init__.py:95: UserWarning: pyproj unable to set database path.\n",
      "  _pyproj_global_context_initialize()\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def extract_valid_shapes(tif_file):\n",
    "    \"\"\"Extracts valid (non-nodata) regions as polygons from a TIFF file.\"\"\"\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        band = src.read(1)\n",
    "        mask = band != src.nodata  # Mask valid data\n",
    "        \n",
    "        # Extract polygons\n",
    "        return [shape(geom) for geom, _ in shapes(band, mask=mask, transform=src.transform)]\n",
    "\n",
    "def process_tifs_parallel(tif_files):\n",
    "    \"\"\"Processes TIFFs in parallel and extracts valid polygons.\"\"\"\n",
    "    polygons = []\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = executor.map(extract_valid_shapes, tif_files)\n",
    "        for result in results:\n",
    "            polygons.extend(result)  # Flatten list\n",
    "    return polygons\n",
    "\n",
    "def save_to_gpkg(polygons, gpkg_output, crs):\n",
    "    \"\"\"Saves polygons to a GeoPackage.\"\"\"\n",
    "    gdf = gpd.GeoDataFrame(geometry=polygons, crs=crs)\n",
    "    gdf.to_file(gpkg_output, driver=\"GPKG\")\n",
    "    print(f'saving...\\n{gpkg_output}')\n",
    "\n",
    "def tileindex(tif_files, gpkg_output):\n",
    "    \"\"\"Main function to extract valid regions from TIFFs and save to GeoPackage.\"\"\"\n",
    "    if not tif_files:\n",
    "        raise ValueError(\"No TIFF files provided.\")\n",
    "\n",
    "    with rasterio.open(tif_files[0]) as src:\n",
    "        crs = src.crs  # Use CRS from the first file\n",
    "\n",
    "    polygons = process_tifs_parallel(tif_files)\n",
    "    save_to_gpkg(polygons, gpkg_output, crs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdaltindex(fo, dir):\n",
    "    cmd = f\"gdaltindex -f GPKG {fo} {dir}/*.tif\"\n",
    "    os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornl_rerpj_dir = \"/media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj\"\n",
    "dtm_gpkg = os.path.join(ornl_rerpj_dir, 'dtm.gpkg')\n",
    "dsm_gkpg = os.path.join(ornl_rerpj_dir, 'dsm.gpkg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdaltindex(dsm_gkpg, ornl_dsm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdaltindex(dtm_gpkg, ornl_dtm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = gpd.read_file(dsm_gkpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mosaic by closer things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "tif_files =  idtm_files# [\"file1.tif\", \"file2.tif\", \"file3.tif\"]\n",
    "gpkg_output = dtm_gpkg\n",
    "#tileindex(tif_files, gpkg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_files =  idsm_files# [\"file1.tif\", \"file2.tif\", \"file3.tif\"]\n",
    "gpkg_output = dsm_gkpg\n",
    "#tileindex(tif_files, gpkg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Function to get the bounding box of a TIFF file\n",
    "def get_bounding_box(tif_file):\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        bounds = src.bounds  # Returns (left, bottom, right, top)\n",
    "        return box(bounds.left, bounds.bottom, bounds.right, bounds.top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "bounding_boxes = [get_bounding_box(tif) for tif in tif_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "17\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Convert bounding boxes to centroids (geographic center points)\n",
    "centroids = [(bbox.centroid.x, bbox.centroid.y) for bbox in bounding_boxes]\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "eps = 1.2#0.9 # Maximum distance between points to be considered in the same cluster (in degrees)\n",
    "min_samples = 2#2  # Minimum number of points to form a cluster\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples).fit(centroids)\n",
    "\n",
    "# Get cluster labels\n",
    "labels = db.labels_\n",
    "print(np.unique(labels))\n",
    "print(print(len(np.unique(labels))))\n",
    "\n",
    "# Group files by cluster\n",
    "clusters = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(tif_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "from sklearn.cluster import DBSCAN\n",
    "import subprocess\n",
    "\n",
    "# Step 1: Function to get the bounding box of a TIFF file\n",
    "def get_bounding_box(tif_file):\n",
    "    with rasterio.open(tif_file) as src:\n",
    "        bounds = src.bounds  # Returns (left, bottom, right, top)\n",
    "        return box(bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
    "\n",
    "# Step 2: Function to set nodata value for a TIFF file\n",
    "def set_nodata_value(input_file, nodata_value=-9999):\n",
    "    with rasterio.open(input_file, 'r+') as src:\n",
    "        src.nodata = nodata_value\n",
    "\n",
    "# Step 3: Function to merge TIFF files using GDAL with nodata set to -9999\n",
    "def merge_tiffs(input_files, output_file, nodata_value=-9999):\n",
    "    command = [\n",
    "        \"gdal_merge.py\",\n",
    "        \"-o\", output_file,\n",
    "        \"-a_nodata\", str(nodata_value),  # Set nodata value\n",
    "        \"-of\", \"GTiff\"                  # Output format (GeoTIFF)\n",
    "    ] + input_files\n",
    "    subprocess.run(command)\n",
    "\n",
    "# Step 4: Main Workflow\n",
    "def group_and_merge_tifs(outdir, tif_files, eps=0.1, min_samples=2, nodata_value=-9999):\n",
    "    # Step 4.1: Extract bounding boxes and centroids\n",
    "    bounding_boxes = [get_bounding_box(tif) for tif in tif_files]\n",
    "    centroids = [(bbox.centroid.x, bbox.centroid.y) for bbox in bounding_boxes]\n",
    "\n",
    "    # Step 4.2: Apply DBSCAN clustering\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples).fit(centroids)\n",
    "    labels = db.labels_\n",
    "    print(np.unique(labels))\n",
    "    print('Ulabels',print(len(np.unique(labels))))\n",
    "\n",
    "    # Step 4.3: Group files by cluster\n",
    "    clusters = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        clusters[label].append(tif_files[i])\n",
    "\n",
    "    # Step 4.4: Standardize nodata values for all input files\n",
    "    for tif_file in tif_files:\n",
    "        set_nodata_value(tif_file, nodata_value=nodata_value)\n",
    "\n",
    "    # Step 4.5: Merge files in each cluster\n",
    "    for cluster_id, files in clusters.items():\n",
    "        if cluster_id != -1:  # Ignore noise points (-1 label)\n",
    "            output_file = f\"{outdir}/merged_cluster_{cluster_id}.tif\"\n",
    "            merge_tiffs(files, output_file, nodata_value=nodata_value)\n",
    "            print(f\"Merged {len(files)} files into {output_file}\")\n",
    "\n",
    "# # Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     # List of your TIFF files\n",
    "\n",
    "\n",
    "#     # Run the workflow\n",
    "#     group_and_merge_tifs(\n",
    "#         tif_files=tif_files,\n",
    "#         eps=0.1,               # Maximum distance between points to be considered in the same cluster (in degrees)\n",
    "#         min_samples=2,         # Minimum number of files required to form a cluster\n",
    "#         nodata_value=-9999     # Nodata value for merged files\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "17\n",
      "Ulabels None\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 891 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_0.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 531 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_1.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 133 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_2.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 45 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_3.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 29 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_4.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 57 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_5.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 216 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_6.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 18 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_7.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 23 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_8.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 20 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_9.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 415 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_10.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 201 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_11.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 139 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_12.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 120 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_13.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 193 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_14.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 37 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_15.tif\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "Merged 42 files into /media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster/merged_cluster_16.tif\n"
     ]
    }
   ],
   "source": [
    "ornl_dsm_cluster_dir = \"/media/ljp238/12TBWolf/ARCHIEVE/Brazil_ORNL_tif/meta_stateless/reproj/dsm_cluster\"\n",
    "os.makedirs(ornl_dsm_cluster_dir, exist_ok=True)\n",
    "\n",
    "group_and_merge_tifs(outdir=ornl_dsm_cluster_dir, tif_files=idsm_files, eps=1.2, min_samples=2, nodata_value=-9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EBA repro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "samlidar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
